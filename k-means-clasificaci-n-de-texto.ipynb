{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2361525,"sourceType":"datasetVersion","datasetId":1426271}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **K-Means aplicado a texto**\n\nEl presente documento busca entender como funciona el algoritmo K-means en el análisis de texto, en el marco de estudio del procesamiento del lenguaje natural. \n\nTomamos como base un set de datos de clasificación de peliculas con el objetivo de subclasificar las mismas en mas opciones que \"positiva\" o \"negativa\" ","metadata":{}},{"cell_type":"markdown","source":"## **Preparación de datos**\n\n### **Carga de datos**\n\nPara el uso practico y para lograr entender como funciona limitamos el dataset a la solo las primeras 100 filas. \n\nComo vamos a modificar la columna de interes creamos una copia para despues poder estudiar en profundidad el resultado. \n\nMostramos los primeros 2 solo para ver como va quedando. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd \n\ndatos = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews-spanish/IMDB Dataset SPANISH.csv\")\ndatos = datos.head(100)\ndatos[\"review_es_original\"] = datos[\"review_es\"]\ndatos.head(2)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-28T23:36:06.584576Z","iopub.execute_input":"2024-08-28T23:36:06.585109Z","iopub.status.idle":"2024-08-28T23:36:08.630579Z","shell.execute_reply.started":"2024-08-28T23:36:06.585059Z","shell.execute_reply":"2024-08-28T23:36:08.628981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Normalizar**\n\nAntes de procesar el texto convertir a minúsculas, eliminar acentos, etc. Esto para garantizar que palabras iguales que estén escritas de distintas formas se tomen como diferentes. \n\nEn este caso usaremos la libreria unicodedata. \n\n**Por ejemplo, observemos el siguiente texto:**\n","metadata":{}},{"cell_type":"code","source":"print(datos[\"review_es\"][1])","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:08.633537Z","iopub.execute_input":"2024-08-28T23:36:08.634112Z","iopub.status.idle":"2024-08-28T23:36:08.642427Z","shell.execute_reply.started":"2024-08-28T23:36:08.634051Z","shell.execute_reply":"2024-08-28T23:36:08.640694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Aplicamos la normalización en 2 partes:**\n\n* Normalización ‘NFD’ (Normalization Form D). Esta forma descompone los caracteres acentuados en sus componentes básicos. Por ejemplo, la letra “á” se descompone en “a” y el acento (En este paso incluimos la función de pandas para pasar todo a minuscula).\n* Encode ('ascii', 'ignore'): Convierte cada cadena de texto a bytes ASCII, ignorando los caracteres que no pueden ser convertidos a ASCII. Esto elimina los caracteres acentuados y otros caracteres especiales.\n\nLuego Decode('utf-8') Convierte los bytes de vuelta a una cadena de texto en formato UTF-8.\n\n> Nota: Se tiene que usar lamda dado que no podemos aplicar la normalización a la serie de datos completa, hay que hacerlo por cada elemento. \n","metadata":{}},{"cell_type":"code","source":"import unicodedata\n\ndatos[\"review_es\"] = datos[\"review_es\"].apply(lambda x: unicodedata.normalize('NFD', x).lower())\ndatos[\"review_es\"] = datos[\"review_es\"].apply(lambda x: x.encode('ascii', 'ignore').decode('utf-8'))","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:08.644376Z","iopub.execute_input":"2024-08-28T23:36:08.644856Z","iopub.status.idle":"2024-08-28T23:36:08.662531Z","shell.execute_reply.started":"2024-08-28T23:36:08.644807Z","shell.execute_reply":"2024-08-28T23:36:08.66086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Como podemos observar se aplicaron las correcciones al texto:**","metadata":{}},{"cell_type":"code","source":"print(datos[\"review_es\"][1])","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:08.665603Z","iopub.execute_input":"2024-08-28T23:36:08.66615Z","iopub.status.idle":"2024-08-28T23:36:08.676123Z","shell.execute_reply.started":"2024-08-28T23:36:08.666081Z","shell.execute_reply":"2024-08-28T23:36:08.674273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Stop Words**\n\nLas stop words (o palabras vacías) son palabras que, por sí solas, no aportan mucho significado y suelen ser ignoradas por los motores de búsqueda al indexar contenido. Estas palabras incluyen artículos, preposiciones, conjunciones y pronombres, entre otras. El objetivo de ignorarlas es centrarse en las palabras clave más relevantes para mejorar la eficiencia en la búsqueda y el análisis de texto.\n\nLista de stop words comunes en español\nAlgunas stop words comunes en español incluyen:\n\n* Artículos: el, la, los, las, un, una, unos, unas\n* Preposiciones: a, ante, bajo, con, contra, de, desde, en, entre, hacia, hasta, para, por, según, sin, sobre, tras\n* Conjunciones: y, o, pero, aunque, sino, que\n* Pronombres: yo, tú, él, ella, nosotros, vosotros, ellos, ellas, me, te, se, nos, os, le, les\n\n> Nota: Para este caso practico al ser reseñas de peliculas se agregó a stopwords pelicula y escena. \n\n*Usamos la libreria nltk que ya tiene una lista de stopwords en español:*","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nstop_words_es = stopwords.words('spanish')\nstop_words_es.extend([\"pelicula\", \"peliculas\", \"escena\", \"escenas\"])\nprint(f\"{stop_words_es[0:5]}, entre otras.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:08.677891Z","iopub.execute_input":"2024-08-28T23:36:08.678371Z","iopub.status.idle":"2024-08-28T23:36:08.691238Z","shell.execute_reply.started":"2024-08-28T23:36:08.678327Z","shell.execute_reply":"2024-08-28T23:36:08.689485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Vectorizamos el texto** \n\nSe debe pasar el texto a valores numericos: para esto se convierte todo el set (tomamos la columna review_es) en una matriz, donde cada fila va a ser una reseña y cada columna una palabra. La matriz va a alojar la cantidad de veces que la palabra se repite en el texto.\n\nPasamos como parámetro las stopwords que definimos en el paso anterior para que no las tenga en cuenta. \n\n> Nota: el resultado es una matriz dispersa.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer(stop_words=stop_words_es)\nmatriz_textos = vectorizer.fit_transform(datos[\"review_es\"])\n\nmatriz_textos","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:08.6933Z","iopub.execute_input":"2024-08-28T23:36:08.693862Z","iopub.status.idle":"2024-08-28T23:36:08.752752Z","shell.execute_reply.started":"2024-08-28T23:36:08.693803Z","shell.execute_reply":"2024-08-28T23:36:08.750927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explicación: Matriz dispersa (sparse matrix)\n\nEs un tipo de matriz en la que la mayoría de sus elementos son cero. A diferencia de una matriz densa, donde la mayoría de los elementos tienen valores distintos de cero, las matrices dispersas son comunes en situaciones donde los datos son escasos o tienen muchos valores nulos.\n\nCompressed Sparse Row (CSR): En lugar de almacenar todos los elementos de la matriz (incluyendo los ceros), CSR solo almacena los valores distintos de cero junto con información adicional para reconstruir la matriz completa cuando sea necesario. Esto permite ahorrar una gran cantidad de memoria, especialmente cuando la matriz es muy grande y dispersa.\n\nEl resultado tiene 10288 elementos distintos de cero, 100 filas y 5206 columnas.","metadata":{}},{"cell_type":"markdown","source":"## **Para entender el resultado**\n\nSolo para entender como funciona... bajamos la matriz a un sheet de excel. Para esto debemos pasarla de una matriz densa a una matriz común. ","metadata":{}},{"cell_type":"code","source":"matriz_densa = matriz_textos.toarray()\nnombres_columnas = vectorizer.get_feature_names_out()\ndf = pd.DataFrame(matriz_densa, columns=nombres_columnas)\ndf.to_excel(\"mi_matriz_de_textos.xlsx\", index=False) ","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:08.75477Z","iopub.execute_input":"2024-08-28T23:36:08.755253Z","iopub.status.idle":"2024-08-28T23:36:26.634342Z","shell.execute_reply.started":"2024-08-28T23:36:08.755201Z","shell.execute_reply":"2024-08-28T23:36:26.632987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Por ejemplo: \n\nDel análisis del excel podemos observar que para el indice cero que corresponde a la primer reseña, la palabra violencia se repite 4 veces.\n\nPara mostrarlo filtramos de la matriz:","metadata":{}},{"cell_type":"code","source":"df.iloc[0:10,5090:6000]","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:37.775797Z","iopub.execute_input":"2024-08-28T23:36:37.776287Z","iopub.status.idle":"2024-08-28T23:36:37.806673Z","shell.execute_reply.started":"2024-08-28T23:36:37.776241Z","shell.execute_reply":"2024-08-28T23:36:37.805308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Si observamos la primer reseña esto es efectivamente correcto** \n\n\"Uno de los otros críticos ha mencionado que después de ver solo 1 Oz Episodio, estará enganchado. Tienen razón, ya que esto es exactamente lo que sucedió conmigo. La primera cosa que me golpeó sobre Oz fue su brutalidad y sus escenas de **violencia** inconfiadas, que se encuentran a la derecha de la palabra. Confía en mí, este no es un espectáculo para los débiles de corazón o tímido. Este espectáculo no extrae punzones con respecto a las drogas, el sexo o la **violencia**. Es Hardcore, en el uso clásico de la palabra. Se llama OZ, ya que es el apodo dado al Penitenciario del Estado de Seguridad Máximo de Oswald. Se centra principalmente en la ciudad de Emeralda, una sección experimental de la prisión donde todas las células tienen frentes de vidrio y se enfrentan hacia adentro, por lo que la privacidad no es alta en la agenda. Em City es el hogar de muchos ... Fariarios, musulmanes, gangstas, latinos, cristianos, italianos, irlandeses y más ... así que las esposas, las miradas de muerte, las relaciones peligrosas y los acuerdos sombreados nunca están lejos. Yo diría el principal atractivo de El espectáculo se debe al hecho de que va donde otros espectáculos no se atreverían. Olvídate de las imágenes bonitas pintadas para las audiencias convencionales, olvidan el encanto, olviden el romance ... Oz no se mete. El primer episodio que he visto me sorprendió tan desagradable que fue surrealista, no podía decir que estaba listo para ello, pero cuando observé más, desarrollé un gusto por Oz, y me acostumbré a los altos niveles de **violencia** gráfica. No solo la **violencia**, sino la injusticia (Guardias torcidas que se vendrán por un níquel, los reclusos que se matarán en orden y se alejarán con él, de manera educada, los reclusos de clase media se convirtieron en perras de la prisión debido a su falta de habilidades callejeras O experiencia en la prisión) viendo oz, puede sentirse cómodo con lo que es incómodo visualización ... eso es si puedes ponerte en contacto con tu lado más oscuro.\"","metadata":{}},{"cell_type":"markdown","source":"## **Creamos un modelo K-Means**\n\nImportamos K-Means desde Skitlearn\n\nCreamos el modelo y le indicamos la cantidad de cluster objetivo. El valor n_init establece cuantas veces se recalculan los centroides.\n\nLuego ejecutamos el modelo con fit_predict, tomando como referencia la matriz de texto. ","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nmodelo = KMeans(n_clusters=6, n_init=10)\npredicciones = modelo.fit_predict(matriz_textos)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:26.665841Z","iopub.execute_input":"2024-08-28T23:36:26.666551Z","iopub.status.idle":"2024-08-28T23:36:26.782293Z","shell.execute_reply.started":"2024-08-28T23:36:26.666479Z","shell.execute_reply":"2024-08-28T23:36:26.781238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Aplicamos las predicciones al set de datos**\n\nCreamos una columna nueva en el dataset original y le aplicamos las predicciones","metadata":{}},{"cell_type":"code","source":"datos[\"clasifica\"] = predicciones\ndatos.to_excel(\"resultado.xlsx\")\ndatos.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:38:08.774672Z","iopub.execute_input":"2024-08-28T23:38:08.775262Z","iopub.status.idle":"2024-08-28T23:38:08.910548Z","shell.execute_reply.started":"2024-08-28T23:38:08.775209Z","shell.execute_reply":"2024-08-28T23:38:08.909307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Conclusión** \n\nEn relación a la versión 1, incluyendo un filtro para las *(StopWords)* el desempeño del algoritmo mejoró bastante. \n\nEn el ejemplo a continuación vemos como se han clasificado todas las reseñas que poseen la palabra \"Violencia\". Sin profundizar en el análisis en relación a la primer ejecución observamos que la mayoria de las reseñas con la palabra violencia se clasificaron en el mismo cluster. \n\n> Nota: Mas abajo se muestra la nube de palabras de dicho cluster.","metadata":{}},{"cell_type":"code","source":"df_filtrado = datos[datos['review_es'].str.contains('violencia')]\ndf_filtrado","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:26.903298Z","iopub.execute_input":"2024-08-28T23:36:26.903775Z","iopub.status.idle":"2024-08-28T23:36:26.92449Z","shell.execute_reply.started":"2024-08-28T23:36:26.903731Z","shell.execute_reply":"2024-08-28T23:36:26.922667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Nube de palabras sin aplicar stopwords**","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ntexto = \" \".join(datos[\"review_es\"].astype(str))\n \nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto)\n\n# Visualizar el wordcloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:26.926095Z","iopub.execute_input":"2024-08-28T23:36:26.926685Z","iopub.status.idle":"2024-08-28T23:36:28.342306Z","shell.execute_reply.started":"2024-08-28T23:36:26.926626Z","shell.execute_reply":"2024-08-28T23:36:28.341194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Nube de palabras luego de aplicar stopwords**","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ntexto = \" \".join(datos[\"review_es\"].astype(str))\n \nwordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stop_words_es).generate(texto)\n\n# Visualizar el wordcloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:28.34401Z","iopub.execute_input":"2024-08-28T23:36:28.344827Z","iopub.status.idle":"2024-08-28T23:36:29.685389Z","shell.execute_reply.started":"2024-08-28T23:36:28.34477Z","shell.execute_reply":"2024-08-28T23:36:29.684121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Nube de palabras solo del cluster 0**","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ncluster_reviews = datos[datos[\"clasifica\"] == 0][\"review_es\"]\n\ntexto = \" \".join(cluster_reviews.astype(str))\n \nwordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stop_words_es).generate(texto)\n\n# Visualizar el wordcloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:40:42.691988Z","iopub.execute_input":"2024-08-28T23:40:42.692657Z","iopub.status.idle":"2024-08-28T23:40:44.070507Z","shell.execute_reply.started":"2024-08-28T23:40:42.692601Z","shell.execute_reply":"2024-08-28T23:40:44.06926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Nube de palabras de reseñas que contienen la palabra violencia**","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ncluster_reviews = df_filtrado['review_es']\n\ntexto = \" \".join(cluster_reviews.astype(str))\n \nwordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stop_words_es).generate(texto)\n\n# Visualizar el wordcloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T23:36:30.832287Z","iopub.execute_input":"2024-08-28T23:36:30.833065Z","iopub.status.idle":"2024-08-28T23:36:32.094357Z","shell.execute_reply.started":"2024-08-28T23:36:30.833008Z","shell.execute_reply":"2024-08-28T23:36:32.092889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Para continuar investigando***\n\nEn el cluster cero como podemos observar se agruparon reseñas que principalmente contienen la palabra \"Si\", \"Ma\" y \"Ver\"... es esto util? \n\n*Las reseñas con la palabra violencia* fueron al mismo cluster... destacando las mismas palabras que las mencionadas anteriormente. ","metadata":{}}]}